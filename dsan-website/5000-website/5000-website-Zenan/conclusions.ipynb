{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Conclusions\"\n",
    "format: \n",
    "  html:\n",
    "    code-fold: true\n",
    "execute: \n",
    "  enabled: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project summary:\n",
    "In conclusion, this project centers around the competition between electric vehicles (EVs) and traditional gas-powered cars. With a prevalent influx of negative news impacting public perception and fostering skepticism regarding the general safety of EVs, this study has delved into predictive modeling. Utilizing various models, including Naive Bayes and Random Forest, simulations were conducted to predict the outcomes of accidents involving both EVs and gas cars.\n",
    "\n",
    "A crucial aspect of the project involved identifying the most influential features contributing to the frequency of accidents. By pinpointing these features, the study aims to provide valuable insights that law enforcement authorities can leverage to address and mitigate potential risks. This holistic approach seeks to enhance the overall understanding of accident patterns, fostering a safer environment and addressing concerns surrounding EV safety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collected for analysis\n",
    "1. Tesla Deaths - Deaths    link to the dataset: <https://www.kaggle.com/datasets/thedevastator/tesla-accident-fatalities-analysis-and-statistic>\n",
    "2. Traffic Accidents and Vehicles (gas car)    link to the dataset: <https://www.kaggle.com/datasets/tsiaras/uk-road-safety-accidents-and-vehicles>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and exploring \n",
    "1. The data cleaning phase involves eliminating irrelevant columns and modifying variable formats to facilitate analysis. Rather than indiscriminately discarding rows with missing values, a strategy is employed to replace these gaps with the most probable values. This ensures that no information is unnecessarily discarded during the data processing.\n",
    "\n",
    "![Tackle with null values](./images/dataclean.png){width=500}\n",
    "\n",
    "2. The data exploration phase encompasses visualizing the distribution of individual variables and applying an unsupervised learning method to categorize the dataset into smaller groups, revealing distinctive features within each subgroup. Additionally, an examination of the correlation coefficients between variables is conducted to identify any unusual patterns within the dataset.\n",
    "\n",
    "![Visualisation of the unsupervised learning](./images/dataexplore.png){width=500}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes and Decision Tree\n",
    "1. I employed the Naive Bayes method to forecast the outcome of a simulated accident, utilizing a trained model based on the dataset titled \"Traffic Accidents and Vehicles (gas car).\" Subsequently, I computed a classification report to assess the overall predictive accuracy. In addition to the classification report, I substantiated my assertion that the Gaussian Naive Bayes model outperforms random guessing by presenting a ROC curve plot.\n",
    "\n",
    "![Classification report of Naïve Bayes model](./images/naivebayes.png){width=500}\n",
    "\n",
    "2. In the decision tree section, both decision tree and random forest models were employed. To optimize the decision tree model, the focus was on determining the optimal number of layers. This involved using a loop to identify the best value, followed by retraining the decision tree model on the testing dataset. However, the obtained confusion matrix revealed a limitation in predicting positive cases, particularly for fatally serious accidents. Subsequently, a more complex model, the random forest, was employed. \n",
    "\n",
    "In addition to generating the classification report, the study involved identifying the most influential feature affecting the outcome of a simulated accident within the random forest model.\n",
    "\n",
    "::: {layout-ncol=2}\n",
    "![Accuracy statistics and confusion matrix of Decision Tree](./images/decisiontree.png)\n",
    "\n",
    "![Visualisation of influential features of Random Forest](./images/randomforest.png)\n",
    ":::\n",
    "\n",
    "Below is the classification of the Random Forest:\n",
    "![Classification report of Random Forest](./images/randomresult.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "1. Regarding accuracy, both Naive Bayes and Random Forest models perform similarly well, achieving a predictive accuracy of approximately 73%. However, given that the optimal Random Forest model has 50 estimators, indicating higher computational demands compared to the Gaussian Naive Bayes model, my personal preference leans toward the Naive Bayes model.\n",
    "\n",
    "2. In a broader context, the most influential factor contributing to a potential accident is the hour of the day, irrespective of whether one is driving an electric vehicle or a gas-powered car. Furthermore, the models utilized for predicting the outcome of simulated accidents in both EV and gas-powered car scenarios demonstrate effectiveness.\n",
    "\n",
    "3. By classifying all accidents into smaller groups using K-means and other clustering methods, a closer examination of specific accident types becomes feasible. This, in turn, enables the formulation of targeted law enforcement measures and regulations to address particular accident categories.\n",
    "   \n",
    "![Clustering results for all accidents](./images/clustering.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
