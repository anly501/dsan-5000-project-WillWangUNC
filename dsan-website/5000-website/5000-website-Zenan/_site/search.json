[
  {
    "objectID": "aboutyou.html#backgrounds",
    "href": "aboutyou.html#backgrounds",
    "title": "About Me",
    "section": "Backgrounds:",
    "text": "Backgrounds:\nHey everyone, I am Zenan Wang, commonly known as Will, hailing from Nanjing, China. I completed my undergraduate studies at UNC Chapel Hill, achieving a double major in Mathematics and Statistics. My interests include cycling, fitness activities, and indulging in video games for leisure.\n\nLinkedin link: https://www.linkedin.com/in/zenan-wang-062695260/"
  },
  {
    "objectID": "dataclean.html",
    "href": "dataclean.html",
    "title": "Data gathering",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndf = pd.read_csv(\"./Data/Tesla Deaths - Deaths.csv\")\n\n\n\n\n\n\nCode\nmsno.heatmap(df)\n\n\n\n\n\n\n\n\n\n\n\nCode\nnew_df = pd.DataFrame()\nfor i in range(len(df.columns[:14]),1,-1):\n    new_df.insert(0,df.columns[i],df[df.columns[i]])\ndf = new_df\ndf.head()\n\n\n\n\n\n\n\n\n\nDate\nCountry\nState\nDescription\nDeaths\nTesla driver\nTesla occupant\nOther vehicle\nCyclists/ Peds\nTSLA+cycl / peds\nModel\nAutopilot claimed\nVerified Tesla Autopilot Deaths\n\n\n\n\n0\n1/17/2023\nUSA\nCA\nTesla crashes into back of semi\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n1\n1/7/2023\nCanada\n-\nTesla crashes\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n2\n1/7/2023\nUSA\nWA\nTesla hits pole, catches on fire\n1.0\n-\n1\n-\n-\n1\n-\n-\n-\n\n\n3\n12/22/2022\nUSA\nGA\nTesla crashes and burns\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n4\n12/19/2022\nCanada\n-\nTesla crashes into storefront\n1.0\n-\n-\n-\n1\n1\n-\n-\n-\n\n\n\n\n\n\n\n\n\nCode\nmsno.bar(df)\n\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n\n\n\n\nCode\nfor i in range(5,10):\n    df[df.columns[i]] = df[df.columns[i]].fillna(\"-\")\nfor i in range(11,13):\n    df[df.columns[i]] = df[df.columns[i]].fillna('-')\nmsno.bar(df)\n\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n\n\n\n\nCode\ndf = df.dropna()\nmsno.bar(df)\n\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n\nCode\ndf.columns = ['Date','Country','State','Description','Deaths',\"Tesla_driver\",\"Tesla_occupant\",\"Other_vehicle\",\"CP\",\"tsla+cp\",\"Model\",\"Claimed\",\"VTAD\"]\ndf.head()\n\n\n\n\n\n\n\n\n\nDate\nCountry\nState\nDescription\nDeaths\nTesla_driver\nTesla_occupant\nOther_vehicle\nCP\ntsla+cp\nModel\nClaimed\nVTAD\n\n\n\n\n0\n1/17/2023\nUSA\nCA\nTesla crashes into back of semi\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n1\n1/7/2023\nCanada\n-\nTesla crashes\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n2\n1/7/2023\nUSA\nWA\nTesla hits pole, catches on fire\n1.0\n-\n1\n-\n-\n1\n-\n-\n-\n\n\n3\n12/22/2022\nUSA\nGA\nTesla crashes and burns\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n4\n12/19/2022\nCanada\n-\nTesla crashes into storefront\n1.0\n-\n-\n-\n1\n1\n-\n-\n-\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf.to_csv('./cleandata/cleanTelsa.csv', index=False)\n\n\n\n\n\n\n\n\n\n\nCode\ndata = pd.read_csv('./Data/RoadAccident.csv')\ncolumn_datatypes = set()\nfor column in data.columns:\n    column_datatypes.add(str(data[column].dtype))\nprint(\"The dataset contains {} different data types and they are: {}\".format(len(column_datatypes), \", \".join(column_datatypes)))\nX = data.drop(columns='Accident_Severity')\ny = data['Accident_Severity']\ncount = pd.value_counts(y, sort = True)\ncount.plot(kind = 'bar', rot=0)\nplt.title(\"Distribution of Accident Severity \")\nplt.xlabel(\"Result\")\nplt.ylabel(\"Count\")\n\n\nThe dataset contains 3 different data types and they are: object, int64, float64\n\n\nText(0, 0.5, 'Count')\n\n\n\n\n\n\n\n\n\n\nCode\nnumerical_features = list()\ncategorical_features = list()\nfor column in X.columns:\n    # In the dataset we only have float and int64.\n    if (data[column].dtype == 'float64' or data[column].dtype == 'int64'):\n        numerical_features.append(column)\n    # Categorical\n    elif (data[column].dtype == 'object'):\n        categorical_features.append(column)\nprint('There are {} numerical features in the dataset.'.format(len(numerical_features)))\n\n\nThere are 15 numerical features in the dataset.\n\n\n\n\n\n\n\nCode\nX_num_total = X[numerical_features]\nX_num_total.hist(bins=60,figsize=(20, 10))\nplt.show()\nprint('Number of uniques values of Accident Index: {}'.format(X_num_total['Accident_Index'].nunique()))\n\n\n\n\n\nNumber of uniques values of Accident Index: 75550\n\n\n\n\n\n\n\n\n\n\nCode\nprint('There are {} categorical features in the dataset.'.format(len(categorical_features)))\nX_cat_total = X[categorical_features]\nprint('Unique values for each categorical column are:\\n {}'.format(X_cat_total.nunique()))\n\n\nThere are 17 categorical features in the dataset.\nUnique values for each categorical column are:\n Region                        11\nUrban_or_Rural_Area            2\nX1st_Road_Class                6\nRoad_Type                      5\nRoad_Surface_Conditions        5\nWeather                        6\nHigh_Wind                      2\nLights                         4\nDatetime                   67926\nJunction_Detail                8\nJunction_Location              9\nX1st_Point_of_Impact           5\nDriver_Journey_Purpose         5\nPropulsion_Code                2\nVehicle_Make                  25\nVehicle_Category               6\nVehicle_Manoeuvre             11\ndtype: int64\n\n\n\n\nCode\ndata['Datetime']\n\n\n0        1/19/2010 17:30\n1         2/8/2010 11:24\n2          3/3/2010 6:25\n3         3/4/2010 13:35\n4        3/12/2010 16:05\n              ...       \n75545     3/6/2014 18:20\n75546    5/24/2014 15:50\n75547     9/8/2014 12:06\n75548    4/18/2014 15:52\n75549    8/27/2014 16:16\nName: Datetime, Length: 75550, dtype: object\n\n\n\n\n\n\n\nCode\nX = X.drop(columns=['Accident_Index','Datetime'])\n\n\n\n\n\n\n\nCode\nplt.subplots(figsize=(15,8))\nsns.heatmap(X_num_total.corr(), cmap=\"YlGnBu\", annot=True)\nplt.title('Correlation Matrix')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCode\nX.to_csv('./cleandata/cleanUKgas.csv', index=False)\n\n\n\n\n\n\n\n\n\n\nCode\ndf = pd.read_csv('./Data/newapiTesla.csv')\ndef count_word_frequencies(data_frame, column_name, target_words):\n    text = ' '.join(data_frame[column_name])\n    words = text.split()\n    word_counts = {word: words.count(word) for word in set(target_words)}\n    return word_counts\n\ntarget_words = ['deadly', 'flawed', 'death', 'injury', 'casualty', 'accident', 'casualties', 'problem', 'bad', 'negative']\nword_frequencies = count_word_frequencies(df, 'title', target_words)\nfor word, count in word_frequencies.items():\n    print(f\"{word}: {count}\")\n\nplt.bar(word_frequencies.keys(), word_frequencies.values())\nplt.xlabel('Words')\nplt.ylabel('Frequency')\nplt.title('Word Frequencies in title')\nplt.show()\n\n\nbad: 0\nnegative: 0\ncasualties: 0\ndeadly: 0\nproblem: 0\ndeath: 1\ncasualty: 0\naccident: 1\nflawed: 1\ninjury: 0\n\n\n\n\n\n\n\nCode\nword_frequencies = count_word_frequencies(df, 'content', target_words)\nfor word, count in word_frequencies.items():\n    print(f\"{word}: {count}\")\n\nplt.bar(word_frequencies.keys(), word_frequencies.values())\nplt.xlabel('Words')\nplt.ylabel('Frequency')\nplt.title('Word Frequencies in content')\nplt.show()\n\n\nbad: 2\nnegative: 0\ncasualties: 0\ndeadly: 0\nproblem: 0\ndeath: 2\ncasualty: 0\naccident: 8\nflawed: 0\ninjury: 0"
  },
  {
    "objectID": "dataclean.html#first-dataset-tesla-deaths",
    "href": "dataclean.html#first-dataset-tesla-deaths",
    "title": "Data gathering",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndf = pd.read_csv(\"./Data/Tesla Deaths - Deaths.csv\")\n\n\n\n\n\n\nCode\nmsno.heatmap(df)\n\n\n\n\n\n\n\n\n\n\n\nCode\nnew_df = pd.DataFrame()\nfor i in range(len(df.columns[:14]),1,-1):\n    new_df.insert(0,df.columns[i],df[df.columns[i]])\ndf = new_df\ndf.head()\n\n\n\n\n\n\n\n\n\nDate\nCountry\nState\nDescription\nDeaths\nTesla driver\nTesla occupant\nOther vehicle\nCyclists/ Peds\nTSLA+cycl / peds\nModel\nAutopilot claimed\nVerified Tesla Autopilot Deaths\n\n\n\n\n0\n1/17/2023\nUSA\nCA\nTesla crashes into back of semi\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n1\n1/7/2023\nCanada\n-\nTesla crashes\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n2\n1/7/2023\nUSA\nWA\nTesla hits pole, catches on fire\n1.0\n-\n1\n-\n-\n1\n-\n-\n-\n\n\n3\n12/22/2022\nUSA\nGA\nTesla crashes and burns\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n4\n12/19/2022\nCanada\n-\nTesla crashes into storefront\n1.0\n-\n-\n-\n1\n1\n-\n-\n-\n\n\n\n\n\n\n\n\n\nCode\nmsno.bar(df)\n\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n\n\n\n\nCode\nfor i in range(5,10):\n    df[df.columns[i]] = df[df.columns[i]].fillna(\"-\")\nfor i in range(11,13):\n    df[df.columns[i]] = df[df.columns[i]].fillna('-')\nmsno.bar(df)\n\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n\n\n\n\nCode\ndf = df.dropna()\nmsno.bar(df)\n\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n\nCode\ndf.columns = ['Date','Country','State','Description','Deaths',\"Tesla_driver\",\"Tesla_occupant\",\"Other_vehicle\",\"CP\",\"tsla+cp\",\"Model\",\"Claimed\",\"VTAD\"]\ndf.head()\n\n\n\n\n\n\n\n\n\nDate\nCountry\nState\nDescription\nDeaths\nTesla_driver\nTesla_occupant\nOther_vehicle\nCP\ntsla+cp\nModel\nClaimed\nVTAD\n\n\n\n\n0\n1/17/2023\nUSA\nCA\nTesla crashes into back of semi\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n1\n1/7/2023\nCanada\n-\nTesla crashes\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n2\n1/7/2023\nUSA\nWA\nTesla hits pole, catches on fire\n1.0\n-\n1\n-\n-\n1\n-\n-\n-\n\n\n3\n12/22/2022\nUSA\nGA\nTesla crashes and burns\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n4\n12/19/2022\nCanada\n-\nTesla crashes into storefront\n1.0\n-\n-\n-\n1\n1\n-\n-\n-\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf.to_csv('./cleandata/cleanTelsa.csv', index=False)"
  },
  {
    "objectID": "dataclean.html#second-data-uk-road-safety-traffic-accidents-and-vehicles-gas-car",
    "href": "dataclean.html#second-data-uk-road-safety-traffic-accidents-and-vehicles-gas-car",
    "title": "Data gathering",
    "section": "",
    "text": "Code\ndata = pd.read_csv('./Data/RoadAccident.csv')\ncolumn_datatypes = set()\nfor column in data.columns:\n    column_datatypes.add(str(data[column].dtype))\nprint(\"The dataset contains {} different data types and they are: {}\".format(len(column_datatypes), \", \".join(column_datatypes)))\nX = data.drop(columns='Accident_Severity')\ny = data['Accident_Severity']\ncount = pd.value_counts(y, sort = True)\ncount.plot(kind = 'bar', rot=0)\nplt.title(\"Distribution of Accident Severity \")\nplt.xlabel(\"Result\")\nplt.ylabel(\"Count\")\n\n\nThe dataset contains 3 different data types and they are: object, int64, float64\n\n\nText(0, 0.5, 'Count')\n\n\n\n\n\n\n\n\n\n\nCode\nnumerical_features = list()\ncategorical_features = list()\nfor column in X.columns:\n    # In the dataset we only have float and int64.\n    if (data[column].dtype == 'float64' or data[column].dtype == 'int64'):\n        numerical_features.append(column)\n    # Categorical\n    elif (data[column].dtype == 'object'):\n        categorical_features.append(column)\nprint('There are {} numerical features in the dataset.'.format(len(numerical_features)))\n\n\nThere are 15 numerical features in the dataset.\n\n\n\n\n\n\n\nCode\nX_num_total = X[numerical_features]\nX_num_total.hist(bins=60,figsize=(20, 10))\nplt.show()\nprint('Number of uniques values of Accident Index: {}'.format(X_num_total['Accident_Index'].nunique()))\n\n\n\n\n\nNumber of uniques values of Accident Index: 75550\n\n\n\n\n\n\n\n\n\n\nCode\nprint('There are {} categorical features in the dataset.'.format(len(categorical_features)))\nX_cat_total = X[categorical_features]\nprint('Unique values for each categorical column are:\\n {}'.format(X_cat_total.nunique()))\n\n\nThere are 17 categorical features in the dataset.\nUnique values for each categorical column are:\n Region                        11\nUrban_or_Rural_Area            2\nX1st_Road_Class                6\nRoad_Type                      5\nRoad_Surface_Conditions        5\nWeather                        6\nHigh_Wind                      2\nLights                         4\nDatetime                   67926\nJunction_Detail                8\nJunction_Location              9\nX1st_Point_of_Impact           5\nDriver_Journey_Purpose         5\nPropulsion_Code                2\nVehicle_Make                  25\nVehicle_Category               6\nVehicle_Manoeuvre             11\ndtype: int64\n\n\n\n\nCode\ndata['Datetime']\n\n\n0        1/19/2010 17:30\n1         2/8/2010 11:24\n2          3/3/2010 6:25\n3         3/4/2010 13:35\n4        3/12/2010 16:05\n              ...       \n75545     3/6/2014 18:20\n75546    5/24/2014 15:50\n75547     9/8/2014 12:06\n75548    4/18/2014 15:52\n75549    8/27/2014 16:16\nName: Datetime, Length: 75550, dtype: object\n\n\n\n\n\n\n\nCode\nX = X.drop(columns=['Accident_Index','Datetime'])\n\n\n\n\n\n\n\nCode\nplt.subplots(figsize=(15,8))\nsns.heatmap(X_num_total.corr(), cmap=\"YlGnBu\", annot=True)\nplt.title('Correlation Matrix')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCode\nX.to_csv('./cleandata/cleanUKgas.csv', index=False)"
  },
  {
    "objectID": "dataclean.html#third-dataset-acquired-using-news-api-and-focused-on-the-topic-of-tesla-related-accident",
    "href": "dataclean.html#third-dataset-acquired-using-news-api-and-focused-on-the-topic-of-tesla-related-accident",
    "title": "Data gathering",
    "section": "",
    "text": "Code\ndf = pd.read_csv('./Data/newapiTesla.csv')\ndef count_word_frequencies(data_frame, column_name, target_words):\n    text = ' '.join(data_frame[column_name])\n    words = text.split()\n    word_counts = {word: words.count(word) for word in set(target_words)}\n    return word_counts\n\ntarget_words = ['deadly', 'flawed', 'death', 'injury', 'casualty', 'accident', 'casualties', 'problem', 'bad', 'negative']\nword_frequencies = count_word_frequencies(df, 'title', target_words)\nfor word, count in word_frequencies.items():\n    print(f\"{word}: {count}\")\n\nplt.bar(word_frequencies.keys(), word_frequencies.values())\nplt.xlabel('Words')\nplt.ylabel('Frequency')\nplt.title('Word Frequencies in title')\nplt.show()\n\n\nbad: 0\nnegative: 0\ncasualties: 0\ndeadly: 0\nproblem: 0\ndeath: 1\ncasualty: 0\naccident: 1\nflawed: 1\ninjury: 0\n\n\n\n\n\n\n\nCode\nword_frequencies = count_word_frequencies(df, 'content', target_words)\nfor word, count in word_frequencies.items():\n    print(f\"{word}: {count}\")\n\nplt.bar(word_frequencies.keys(), word_frequencies.values())\nplt.xlabel('Words')\nplt.ylabel('Frequency')\nplt.title('Word Frequencies in content')\nplt.show()\n\n\nbad: 2\nnegative: 0\ncasualties: 0\ndeadly: 0\nproblem: 0\ndeath: 2\ncasualty: 0\naccident: 8\nflawed: 0\ninjury: 0"
  },
  {
    "objectID": "datagather.html",
    "href": "datagather.html",
    "title": "Data gathering",
    "section": "",
    "text": "In recent years, the automotive industry has witnessed a transformative shift towards sustainable and eco-friendly transportation solutions, exemplified by the increasing popularity of electric vehicles (EVs). Among the trailblazers in this revolution is Tesla, a pioneering company that has significantly contributed to the rise of electric cars on our roads. As society embraces cleaner energy alternatives, concerns about the safety of electric cars, particularly in comparison to their traditional gas-powered counterparts, have become a focal point of discussion. This study endeavors to conduct a comprehensive analysis of traffic accidents involving electric cars, with a specific emphasis on Tesla vehicles, and draw meaningful comparisons with incidents involving traditional gas-powered cars. By examining relevant data, trends, and contributing factors, this research aims to shed light on the safety landscape of electric vehicles, providing valuable insights for both policymakers and the general public as we navigate the evolving landscape of transportation technologies."
  },
  {
    "objectID": "datagather.html#introduction",
    "href": "datagather.html#introduction",
    "title": "Data gathering",
    "section": "",
    "text": "In recent years, the automotive industry has witnessed a transformative shift towards sustainable and eco-friendly transportation solutions, exemplified by the increasing popularity of electric vehicles (EVs). Among the trailblazers in this revolution is Tesla, a pioneering company that has significantly contributed to the rise of electric cars on our roads. As society embraces cleaner energy alternatives, concerns about the safety of electric cars, particularly in comparison to their traditional gas-powered counterparts, have become a focal point of discussion. This study endeavors to conduct a comprehensive analysis of traffic accidents involving electric cars, with a specific emphasis on Tesla vehicles, and draw meaningful comparisons with incidents involving traditional gas-powered cars. By examining relevant data, trends, and contributing factors, this research aims to shed light on the safety landscape of electric vehicles, providing valuable insights for both policymakers and the general public as we navigate the evolving landscape of transportation technologies."
  },
  {
    "objectID": "datagather.html#summary-of-the-data",
    "href": "datagather.html#summary-of-the-data",
    "title": "Data gathering",
    "section": "Summary of the data:",
    "text": "Summary of the data:\n\nCase #: Unique identifier for each case. (String)\nYear: Year of the accident. (Integer)\nDate: Date of the accident. (Date)\nCountry: The country where the accident occurred. (String)\nState: State where the accident occurred. (String)\nDescription: Description of the accident. (String)\nDeaths: Number of Deaths (Int)\nTesla driver: Whether the Tesla driver was killed in the accident. (Boolean)\nTesla occupant: Whether a Tesla occupant was killed in the accident. (Boolean)\nOther Vehicle: whether the Tesla crashed another vehicle (Boolean)\nCyclist/ Peds: Whether Tesla killed a Cyclist/Pedestrian in the accident. (Boolean)\nSLA + cycl / peds: Tesla + Cycle / Pedestrian (Boolean)\nAutopilot claimed: People who have claimed Auto Pilot (Boolean)\nVerified Tesla Autopilot Death: Verified Tesla Autopilot Death (Boolean)\nVerified Tesla Autopilot Death & All Deaths Reported to NHTSA SGO : Verified Tesla\nAutopilot Death & All Deaths Reported to NHTSA SGO (Boolean)\nSource: Source of the data. (String)\nSource: Source of the data. (String)\nSource: Source of the data. (String)\nNote: Note (String)\nModel: Model of the Tesla vehicle involved in the accident. (String)\nSource: Source of the data. (String)\nDeceased 1: 1st Dead person’s Name (String)\nDeceased 2: 2nd Dead person’s Name (String)\nDeceased 3: 3rd Dead person’s Name (String)\nDeceased 4: 4th Dead person’s Name (String)\n\n\nQuick exploration of the data:\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\nfrom nltk import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\n\n\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\23898\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\23898\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n\n\n\n\nOverview of the dataset\n\n\nCode\ndf = pd.read_csv(\"./Data/Tesla Deaths - Deaths.csv\")\ndf.head()\n\n\n\n\n\n\n\n\n\nCase #\nYear\nDate\nCountry\nState\nDescription\nDeaths\nTesla driver\nTesla occupant\nOther vehicle\n...\nVerified Tesla Autopilot Deaths\nVerified Tesla Autopilot Deaths + All Deaths Reported to NHTSA SGO\nUnnamed: 16\nUnnamed: 17\nSource\nNote\nDeceased 1\nDeceased 2\nDeceased 3\nDeceased 4\n\n\n\n\n0\n294.0\n2022.0\n1/17/2023\nUSA\nCA\nTesla crashes into back of semi\n1.0\n1\n-\n-\n...\n-\n-\nhttps://web.archive.org/web/20221222203930/ht...\nhttps://web.archive.org/web/20221222203930/ht...\nhttps://web.archive.org/web/20230118162813/ht...\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n293.0\n2022.0\n1/7/2023\nCanada\n-\nTesla crashes\n1.0\n1\n-\n-\n...\n-\n-\nhttps://web.archive.org/web/20221222203930/ht...\nhttps://web.archive.org/web/20221222203930/ht...\nhttps://web.archive.org/web/20230109041434/ht...\nNaN\nTaren Singh Lal\nNaN\nNaN\nNaN\n\n\n2\n292.0\n2022.0\n1/7/2023\nUSA\nWA\nTesla hits pole, catches on fire\n1.0\n-\n1\n-\n...\n-\n-\nhttps://web.archive.org/web/20221222203930/ht...\nhttps://web.archive.org/web/20221222203930/ht...\nhttps://web.archive.org/web/20230107232745/ht...\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3\n291.0\n2022.0\n12/22/2022\nUSA\nGA\nTesla crashes and burns\n1.0\n1\n-\n-\n...\n-\n-\nhttps://web.archive.org/web/20221222203930/ht...\nhttps://web.archive.org/web/20221222203930/ht...\nhttps://web.archive.org/web/20221222203930/ht...\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\n290.0\n2022.0\n12/19/2022\nCanada\n-\nTesla crashes into storefront\n1.0\n-\n-\n-\n...\n-\n-\nhttps://web.archive.org/web/20221223203725/ht...\nhttps://web.archive.org/web/20221223203725/ht...\nhttps://web.archive.org/web/20221223203725/ht...\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 24 columns"
  },
  {
    "objectID": "datagather.html#summary",
    "href": "datagather.html#summary",
    "title": "Data gathering",
    "section": "Summary:",
    "text": "Summary:\nThe UK government collects and publishes (usually on an annual basis) detailed information about traffic accidents across the country. This information includes, but is not limited to, geographical locations, weather conditions, type of vehicles, number of casualties and vehicle manoeuvres, making this a very interesting and comprehensive dataset for analysis and research.\nThe creation of this dataset was inspired by the one previously published by Dave Fisher-Hickey. However, this current dataset features the following significant improvements over its predecessor:\n\nIt covers a wider date range of events.\nMost of the coded data variables have been transformed to textual strings using relevant lookup tables, enabling more efficient and “human-readable” analysis.\nIt features detailed information about the vehicles involved in the accidents.\n\n\nOverview of the dataset\n\n\nCode\ndata = pd.read_csv('./Data/RoadAccident.csv')\ndata.drop(['Accident_Index','Datetime'], axis = 1,inplace=True) \ndata\n\n\n\n\n\n\n\n\n\nLatitude\nLongitude\nRegion\nUrban_or_Rural_Area\nX1st_Road_Class\nDriver_IMD_Decile\nSpeed_limit\nRoad_Type\nRoad_Surface_Conditions\nWeather\n...\nJunction_Detail\nJunction_Location\nX1st_Point_of_Impact\nDriver_Journey_Purpose\nEngine_CC\nPropulsion_Code\nVehicle_Make\nVehicle_Category\nVehicle_Manoeuvre\nAccident_Severity\n\n\n\n\n0\n51.495653\n-0.179097\nLondon\nUrban\nC\n7\n30\nSingle carriageway\nDry\nFine\n...\nNot at junction or within 20 metres\nNot at or within 20 metres of junction\nFront\nOther/Not known\n1781\nPetrol\nAudi\nCar\nGoing ahead\nSlight\n\n\n1\n51.499635\n-0.209915\nLondon\nUrban\nA\n3\n30\nSingle carriageway\nDry\nFine\n...\nMore than 4 arms (not roundabout)\nMid Junction - on roundabout or on main road\nOffside\nOther/Not known\n2987\nHeavy oil\nMercedes\nCar\nWaiting to go\nSlight\n\n\n2\n51.492515\n-0.168130\nLondon\nUrban\nUnclassified\n5\n30\nSingle carriageway\nDry\nFine\n...\nCrossroads\nMid Junction - on roundabout or on main road\nFront\nJourney as part of work\n998\nPetrol\nNissan\nCar\nGoing ahead\nSlight\n\n\n3\n51.504784\n-0.193863\nLondon\nUrban\nA\n2\n30\nSingle carriageway\nDry\nFine\n...\nT or staggered junction\nMid Junction - on roundabout or on main road\nOffside\nJourney as part of work\n2179\nHeavy oil\nCitroen\nVan\nTurning right\nSlight\n\n\n4\n51.522072\n-0.212927\nLondon\nUrban\nB\n3\n30\nSingle carriageway\nWet or damp\nFine\n...\nT or staggered junction\nApproaching junction or waiting/parked at junc...\nNearside\nJourney as part of work\n2198\nHeavy oil\nFord\nVan\nOvertaking\nSlight\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n75545\n56.531008\n-2.945169\nScotland\nRural\nA\n9\n70\nDual carriageway\nWet or damp\nRaining\n...\nT or staggered junction\nApproaching junction or waiting/parked at junc...\nFront\nOther/Not known\n2199\nHeavy oil\nKia\nCar\nGoing ahead\nFatal_Serious\n\n\n75546\n56.677867\n-3.688719\nScotland\nRural\nA\n10\n70\nDual carriageway\nDry\nFine\n...\nT or staggered junction\nCleared junction or waiting/parked at junction...\nFront\nOther/Not known\n1598\nPetrol\nVauxhall\nCar\nGoing ahead\nFatal_Serious\n\n\n75547\n55.720385\n-2.654035\nScotland\nRural\nA\n9\n60\nSingle carriageway\nDry\nFine\n...\nNot at junction or within 20 metres\nNot at or within 20 metres of junction\nFront\nOther/Not known\n1598\nHeavy oil\nAudi\nCar\nGoing ahead\nFatal_Serious\n\n\n75548\n54.850068\n-4.925632\nScotland\nRural\nB\n5\n60\nSingle carriageway\nDry\nFine\n...\nNot at junction or within 20 metres\nNot at or within 20 metres of junction\nFront\nOther/Not known\n1000\nPetrol\nBMW\nMotorcycle\nGoing ahead\nFatal_Serious\n\n\n75549\n55.158556\n-4.195310\nScotland\nRural\nA\n2\n60\nSingle carriageway\nDry\nFine\n...\nNot at junction or within 20 metres\nNot at or within 20 metres of junction\nFront\nJourney as part of work\n2143\nHeavy oil\nMercedes\nVan\nGoing ahead\nFatal_Serious\n\n\n\n\n75550 rows × 31 columns\n\n\n\n\n\nCheck for the dimension of the data set\n\n\nCode\nprint('There are a total of {} rows and {} columns in the original dataset'.format(data.shape[0],data.shape[1]))\n\n\nThere are a total of 75550 rows and 31 columns in the original dataset\n\n\n\n\nCheck for null values\n\n\nCode\nprint(\"Any null values in the original dataset?: {}\".format(data.isnull().values.any()))\n\n\nAny null values in the original dataset?: False"
  },
  {
    "objectID": "datagather.html#third-dataset-acquired-using-news-api-and-focused-on-the-topic-of-tesla-related-accident",
    "href": "datagather.html#third-dataset-acquired-using-news-api-and-focused-on-the-topic-of-tesla-related-accident",
    "title": "Data gathering",
    "section": "Third dataset (acquired using News-API and focused on the topic of ‘Tesla-related accident’)",
    "text": "Third dataset (acquired using News-API and focused on the topic of ‘Tesla-related accident’)"
  },
  {
    "objectID": "datagather.html#summary-1",
    "href": "datagather.html#summary-1",
    "title": "Data gathering",
    "section": "Summary:",
    "text": "Summary:\nI obtained the ensuing dataset by utilizing the News-API to search for articles pertaining to Tesla accidents. I also processed and curated the articles, saving them in a structured dataset for subsequent analysis. Furthermore, I generated a word cloud to see prominent keywords within the corpus.\n\n\nCode\nimport requests\nimport json\nimport re\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nAPI_KEY='2a0218c20cdd48d29d44f1271c267a25'\nbaseURL = \"https://newsapi.org/v2/everything?\"\n\ntotal_requests= 20\nverbose=True\nTOPIC='Tesla accident'\nURLpost = {'apiKey': API_KEY,\n            'q': '+'+TOPIC,\n            'sortBy': 'relevancy',\n            'totalRequests': 1}\n\nresponse = requests.get(baseURL, URLpost)  \nresponse = response.json() \n\n# PRETTY PRINT\n# https://www.digitalocean.com/community/tutorials/python-pretty-print-json\n\nfrom datetime import datetime\ntimestamp = datetime.now().strftime(\"%Y-%m-%d-H%H-M%M-S%S\")\nwith open(timestamp+'-newapi-raw-data.json', 'w') as file_georetown:\n    json.dump(response, file_georetown, indent=4)\n\ndef string_cleaner(input_string):\n    try: \n        out=re.sub(r\"\"\"\n                    [,.;@#?!&$-]+  # Accept one or more copies of punctuation\n                    \\ *           # plus zero or more copies of a space,\n                    \"\"\",\n                    \" \",          # and replace it with a single space\n                    input_string, flags=re.VERBOSE)\n\n        #REPLACE SELECT CHARACTERS WITH NOTHING\n        out = re.sub('[’.]+', '', input_string)\n\n        #ELIMINATE DUPLICATE WHITESPACES USING WILDCARDS\n        out = re.sub(r'\\s+', ' ', out)\n\n        #CONVERT TO LOWER CASE\n        out=out.lower()\n    except:\n        print(\"ERROR\")\n        out=''\n    return out\n\narticle_list=response['articles']   \narticle_keys=article_list[0].keys()\nindex=0\ncleaned_data1=[];  \nfor article in article_list:\n    tmp=[]\n    if(verbose):\n        print(\"#------------------------------------------\")\n        print(\"#\",index)\n        print(\"#------------------------------------------\")\n\n    for key in article_keys:\n        if(verbose):\n            print(\"----------------\")\n            print(key)\n            print(article[key])\n            print(\"----------------\")\n\n        if(key=='source'):\n            src=string_cleaner(article[key]['name'])\n            tmp.append(src) \n\n        if(key=='author'):\n            author=string_cleaner(article[key])\n\n            if(src in author): \n                print(\" AUTHOR ERROR:\",author);author='NA'\n            tmp.append(author)\n\n        if(key=='title'):\n            tmp.append(string_cleaner(article[key]))\n\n        if(key=='description'):\n            tmp.append(string_cleaner(article[key]))\n\n        if(key=='content'):\n            tmp.append(string_cleaner(article[key]))\n\n        if(key=='publishedAt'):\n           #DEFINE DATA PATERN FOR RE TO CHECK  .* --&gt; wildcard\n            ref = re.compile('.*-.*-.*T.*:.*:.*Z')\n            date=article[key]\n            if(not ref.match(date)):\n               print(\" DATE ERROR:\",date); date=\"NA\"\n            tmp.append(date)\n\n    cleaned_data1.append(tmp)\n    index+=1\n\ndf = pd.DataFrame(cleaned_data1).iloc[:, [2, 5]]\ndf.columns = [\"title\", \"content\"]\ndf.to_csv('./Data/newapiTesla.csv', index=False)\n\n\n\n\nCode\npd.DataFrame(cleaned_data1)\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n\n\n\n\n0\nengadget\nnathan ingraham\ntesla's cybertruck is a dystopian, masturbator...\nits been four years since tesla first announce...\n2023-11-30T22:56:48Z\nits been four years since tesla first announce...\n\n\n1\nboing boing\nnatalie dressed\ntesla knew about defects in \"self-driving\" system\na recent fatal accident involving tesla's auto...\n2023-11-25T19:54:09Z\na recent fatal accident involving tesla's auto...\n\n\n2\nreadwrite\nsam shedden\ntesla in fresh legal battle over self-driving ...\nan american judge has suggested elon musk, amo...\n2023-11-23T13:49:29Z\nan american judge has suggested elon musk, amo...\n\n\n3\nautoblog\njonathon ramsey\nwatch as submerged tesla model x at florida bo...\nfiled under: video,green,weird car news,tesla,...\n2023-11-16T15:13:00Z\nthis incident from october is still missing so...\n\n\n4\nautoblog\nreuters\ntesla launched its own car insurance these dri...\nfiled under: green,tesla,insurance,ownership,e...\n2023-11-21T16:00:00Z\nin february, mark bova purchased a used 2018 t...\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n95\nbarron's\n\nmusk warns of troubles at x what its demise co...\nmicrosoft joins openai board, general motors i...\n2023-11-30T11:50:00Z\nelon musk, chief executive of tesla and the wo...\n\n\n96\nbarron's\nal root\nbuy gm stock, not ford, says wall street\ngm stock caught an upgrade to buy at mizuho gm...\n2023-12-04T12:30:00Z\ngeneral motors shares look set to continue the...\n\n\n97\nseclistsorg\n\nrisks digest 3395\nposted by risks list owner on dec 02risks-list...\n2023-12-02T23:41:34Z\nfrom: risks list owner &lt;risko () csl sri co...\n\n\n98\ntechcrunch\nrebecca bellan\nflorida judge finds tesla, elon musk knew of d...\nthere is \"reasonable evidence\" to conclude tha...\n2023-11-22T13:45:05Z\nthere is “reasonable evidence” to conclude tha...\n\n\n99\nwall-streetro\nNA\njudecător: elon musk „ar fi știut” că sistemul...\ntesla a avut, recent, câștig de cauză într-un ...\n2023-11-23T17:27:49Z\ntesla a avut, recent, câtig de cauz într-un pr...\n\n\n\n\n100 rows × 6 columns\n\n\n\n\n\nCode\ndef generate_word_cloud(my_text):\n    from wordcloud import WordCloud, STOPWORDS\n    import matplotlib.pyplot as plt\n    def plot_cloud(wordcloud):\n        plt.figure(figsize=(40, 30))\n        plt.imshow(wordcloud) \n        plt.axis(\"off\")\n\n    wordcloud = WordCloud(\n        width = 3000,\n        height = 2000, \n        random_state=1, \n        background_color='salmon', \n        colormap='Pastel1', \n        collocations=False,\n        stopwords = STOPWORDS).generate(my_text)\n    plot_cloud(wordcloud)\n    plt.show()\ndf = pd.read_csv(\"./Data/newapiTesla.csv\")\ntext = df.iat[0,1] + df.iat[1,1] + df.iat[2,1]\ngenerate_word_cloud(text)"
  },
  {
    "objectID": "dataexplore.html",
    "href": "dataexplore.html",
    "title": "Data gathering",
    "section": "",
    "text": "EDA, or Exploratory Data Analysis, is a crucial phase in the data analysis process that involves summarizing the main characteristics of a dataset, often with the help of statistical graphics and other data visualization methods. The primary goal of EDA is to understand the structure and key features of the data, discover patterns, identify potential outliers, and generate hypotheses for further analysis.\n\n\n\nTesla Deaths - Deaths\nUK Road Safety: Traffic Accidents and Vehicles (gas car)"
  },
  {
    "objectID": "dataexplore.html#introduction",
    "href": "dataexplore.html#introduction",
    "title": "Data gathering",
    "section": "",
    "text": "EDA, or Exploratory Data Analysis, is a crucial phase in the data analysis process that involves summarizing the main characteristics of a dataset, often with the help of statistical graphics and other data visualization methods. The primary goal of EDA is to understand the structure and key features of the data, discover patterns, identify potential outliers, and generate hypotheses for further analysis.\n\n\n\nTesla Deaths - Deaths\nUK Road Safety: Traffic Accidents and Vehicles (gas car)"
  },
  {
    "objectID": "dataexplore.html#first-dataset-tesla-deaths---deaths",
    "href": "dataexplore.html#first-dataset-tesla-deaths---deaths",
    "title": "Data gathering",
    "section": "First dataset: Tesla Deaths - Deaths",
    "text": "First dataset: Tesla Deaths - Deaths\n\nPre-process the data and take a look at the cleaned data\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\nfrom nltk import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\ndf = pd.read_csv(\"./Data/Tesla Deaths - Deaths.csv\")\nnew_df = pd.DataFrame()\nfor i in range(len(df.columns[:14]),1,-1):\n    new_df.insert(0,df.columns[i],df[df.columns[i]])\ndf = new_df\nfor i in range(5,10):\n    df[df.columns[i]] = df[df.columns[i]].fillna(\"-\")\n    \nfor i in range(11,13):\n    df[df.columns[i]] = df[df.columns[i]].fillna('-')\ndf = df.dropna()\ndf.columns = ['Date','Country','State','Description','Deaths',\"Tesla_driver\",\"Tesla_occupant\",\"Other_vehicle\",\"CP\",\"tsla+cp\",\"Model\",\"Claimed\",\"VTAD\"]\nfor i in range(5,13):\n    for b in range(len(df)):\n        if \"-\"in df[df.columns[i]].values[b]:\n            df[df.columns[i]].values[b] = 0\n        elif \"1\" in df[df.columns[i]].values[b]:\n            df[df.columns[i]].values[b] = 1\n        elif \"2\" in df[df.columns[i]].values[b]:\n            df[df.columns[i]].values[b] = 2\n        elif \"3\" in df[df.columns[i]].values[b]:\n            df[df.columns[i]].values[b] = 3\n        elif \"4\" in df[df.columns[i]].values[b]:\n            df[df.columns[i]].values[b] = 4\n\n\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\23898\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\23898\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n\n\n\n\nCode\ndf.head()\n\n\n\n\n\n\n\n\n\nDate\nCountry\nState\nDescription\nDeaths\nTesla_driver\nTesla_occupant\nOther_vehicle\nCP\ntsla+cp\nModel\nClaimed\nVTAD\n\n\n\n\n0\n1/17/2023\nUSA\nCA\nTesla crashes into back of semi\n1.0\n1\n0\n0\n0\n1\n0\n0\n0\n\n\n1\n1/7/2023\nCanada\n-\nTesla crashes\n1.0\n1\n0\n0\n0\n1\n0\n0\n0\n\n\n2\n1/7/2023\nUSA\nWA\nTesla hits pole, catches on fire\n1.0\n0\n1\n0\n0\n1\n0\n0\n0\n\n\n3\n12/22/2022\nUSA\nGA\nTesla crashes and burns\n1.0\n1\n0\n0\n0\n1\n0\n0\n0\n\n\n4\n12/19/2022\nCanada\n-\nTesla crashes into storefront\n1.0\n0\n0\n0\n1\n1\n0\n0\n0"
  },
  {
    "objectID": "dataexplore.html#start-eda",
    "href": "dataexplore.html#start-eda",
    "title": "Data gathering",
    "section": "Start EDA",
    "text": "Start EDA\n\nThe ‘Date’ variable is not in the default date format\n\n\nCode\ndf.loc[:, \"event_year\"] = 0\ndf.loc[:, \"event_month\"] = 0\ndf.loc[:, \"event_day\"] = 0\nfor i in range(len(df)):\n    df.loc[df.index[i], \"event_year\"] = int(df[\"Date\"].values[i].split('/')[2])\n    df.loc[df.index[i], \"event_month\"] = int(df[\"Date\"].values[i].split('/')[0])\n    df.loc[df.index[i], \"event_day\"] = int(df[\"Date\"].values[i].split('/')[1])\ndf['Date']\n\n\n0       1/17/2023\n1        1/7/2023\n2        1/7/2023\n3      12/22/2022\n4      12/19/2022\n          ...    \n289     7/14/2014\n290      7/4/2014\n291      7/4/2014\n292     11/2/2013\n293      4/2/2013\nName: Date, Length: 294, dtype: object\n\n\n\n\nLet’s see the distribution of crashes around the world\nIt seems that USA has the most accidents, then followed by China and Germany.\n\n\nCode\nx = df[\"Country\"].value_counts().index\ny = df[\"Country\"].value_counts().values\nplt.figure(figsize=(20,8))\nfor i in range(len(x)):\n    height = y[i]\n    plt.text(x[i], height + 0.25, '%.1f' %height, ha='center', va='bottom', size = 12)\nplt.bar(x,y,color='#e35f62')\n\n\n&lt;BarContainer object of 23 artists&gt;\n\n\n\n\n\n\n\nLet’s look at the number of accidents per month\n\n\nCode\nplt.figure(figsize=(20,8))\nx = df[\"event_month\"].value_counts().sort_index().index\ny = df[\"event_month\"].value_counts().sort_index().values\nfor i in range(len(x)):\n    height = y[i]\n    plt.text(x[i], height + 0.5, '%.1f' %height, ha='center', va='bottom', size = 12)\nplt.title(\"Number of accidents per month in the total year\")\nplt.xlabel(\"Month\")\nplt.ylabel(\"Number of events\")\nplt.bar(x,y)\n\n\n&lt;BarContainer object of 12 artists&gt;\n\n\n\n\n\n\n\nIt appears that there are relatively more accidents in November and December.\n\n\nLet’s look at the distribution of the following variables:\n\n\nCode\nd_list = [\"Deaths\",\"Tesla_driver\",\"Tesla_occupant\",\"CP\",\"tsla+cp\",\"Other_vehicle\"]\nlabel = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"]\nplt.figure(figsize = (16,16))\nfor b in range(len(d_list)):\n    size = df[d_list[b]].value_counts().values\n    colors = []\n    label = df[d_list[b]].value_counts().index\n    plt.axis(\"equal\")\n    plt.rc(\"font\",family=\"Malgun Gothic\")\n    plt.rc('legend', fontsize=10)\n    plt.subplot(2,3,b+1)\n    plt.title(d_list[b]+\" - total:\" +str(len(df[d_list[b]])))\n    plt.pie(size,labels=label, autopct = \"%.1f%%\")\n    plt.legend()\n\n\n\n\n\n\n\nThe above collection of pie charts indicates that the majority of the accidents involve one casualty.\n\n\nwhy are there more accidents in November and December? Does that necessarily mean Tesla is maneuverable?\nSince there is a ‘description’ variable in the dataset, which briefly depicts the possible cause and the crash scene, I will classify the accidents into smaller categories.\n\n\nCode\ndef get_wordnet_pos(word):\n    tag = nltk.pos_tag([word])[0][1]\n    if tag.startswith('J'):\n        return wordnet.ADJ\n    elif tag.startswith('V'):\n        return wordnet.VERB\n    elif tag.startswith('N'):\n        return wordnet.NOUN\n    elif tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN\n\ndef lemmatize_text(text):\n    lemmatizer = WordNetLemmatizer()\n    return [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in word_tokenize(text)]\ndata = df[\"Description\"]\n\nlemmatized_data = [lemmatize_text(text) for text in data]\nvectorizer = TfidfVectorizer(stop_words='english')\nX = vectorizer.fit_transform([' '.join(text) for text in lemmatized_data])\n\nkmeans = KMeans(n_clusters= 5, random_state=0)\nkmeans.fit(X)\nclusters = kmeans.predict(X)\n\n\nC:\\Users\\23898\\anaconda\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\n\nLet’s see how the classification goes.\n\n\nCode\ndf[\"Description\"].value_counts()\n\n\nDescription\n Tesla kills pedestrian                         10\n Tesla kills motorcyclist                        6\n Tesla into oncoming traffic                     5\n Tesla rear ends stopped car                     4\n Tesla drives off cliff                          4\n                                                ..\n Tesla crashes into trees                        1\n Multi-crash involving DUI                       1\n Tesla loses control and drives into river       1\n Crash in public area including 20 injuries      1\n Tesla veers into opposite lane                  1\nName: count, Length: 248, dtype: int64\n\n\n\n\nLet’s look at the distribution of the classification\n\n\nCode\ndf.loc[:, \"cluster\"] = 0\nfor i, item in enumerate(df[\"Description\"]):\n    for cluster, description in zip(clusters, data):\n        if item == description:\n            df[\"cluster\"][i] = cluster\naccident_0 = []\naccident_1 = []\naccident_2 = []\naccident_3 = []\naccident_4 = []\nfor i, cluster in enumerate(clusters):\n    if cluster == 0:\n        accident_0.append(data[i])\n    elif cluster == 1:\n        accident_1.append(data[i])\n    elif cluster == 2:\n        accident_2.append(data[i])\n    elif cluster == 3:\n        accident_3.append(data[i])\n    elif cluster == 4:\n        accident_4.append(data[i])\naccident_0_score = []\naccident_1_score = []\naccident_2_score = []\naccident_3_score = []\naccident_4_score = []\n\ndef get_score_list(a,b1):\n    for i in range(len(a)):\n        for b in range(len(df[\"Description\"].value_counts().index)):\n            if df[\"Description\"].value_counts().index[b] == a[i]:\n                b1.append(df[\"Description\"].value_counts().values[b])\n                \nget_score_list(accident_0,accident_0_score)\nget_score_list(accident_1,accident_1_score)\nget_score_list(accident_2,accident_2_score)\nget_score_list(accident_3,accident_3_score)\nget_score_list(accident_4,accident_4_score)\nx = [0,1,2,3,4]\ny = [len(accident_0),len(accident_1),len(accident_2),len(accident_3),len(accident_4)]\nplt.figure(figsize=(20,10))\n# plt.title(\"accident type's counts\")\nplt.xlabel(\"accident type\")\nplt.ylabel(\"counts of accident type\")\nfor i in range(len(x)):\n    height = y[i]\n    plt.text(x[i], height + 0.25, '%.1f' %height, ha='center', va='bottom', size = 12)\nplt.bar(x,y,color='red')\n\n\n&lt;BarContainer object of 5 artists&gt;\n\n\n\n\n\n\n\nLet’s see what type-2 accident is about.\nIt seems that this type of collision has little to do with the maneuverability of Tesla.\n\n\nCode\ndf[df['cluster'] == 2].head(10)\n\n\n\n\n\n\n\n\n\nDate\nCountry\nState\nDescription\nDeaths\nTesla_driver\nTesla_occupant\nOther_vehicle\nCP\ntsla+cp\nModel\nClaimed\nVTAD\nevent_year\nevent_month\nevent_day\ncluster\n\n\n\n\n8\n12/11/2022\nUSA\nMO\nCollision at intersection\n1.0\n0\n0\n1\n0\n0\n0\n0\n0\n2022\n12\n11\n2\n\n\n9\n12/6/2022\nCanada\n-\nTesla veers, collides with truck\n1.0\n1\n0\n0\n0\n0\n0\n0\n0\n2022\n12\n6\n2\n\n\n10\n11/28/2022\nChina\n-\nTesla runs red light, collides with two cars\n2.0\n0\n0\n2\n0\n0\nY\n0\n0\n2022\n11\n28\n2\n\n\n15\n11/12/2022\nUSA\nCA\nMulti-vehicle accident\n1.0\n0\n0\n1\n0\n0\n0\n0\n0\n2022\n11\n12\n2\n\n\n18\n11/4/2022\nUSA\nIL\nCollision at intersection, Tesla driver dies ...\n1.0\n1\n0\n0\n0\n1\n0\n0\n0\n2022\n11\n4\n2\n\n\n20\n10/18/2022\nUSA\nFL\nTesla collides with minivan, engulfed by flames\n4.0\n1\n1\n2\n0\n2\n0\n0\n0\n2022\n10\n18\n2\n\n\n26\n9/16/2022\nUSA\nGA\nTesla loses control and crashes into bus shel...\n1.0\n0\n0\n0\n1\n1\n0\n1\n0\n2022\n9\n16\n2\n\n\n27\n9/13/2022\nUSA\nCA\nTesla runs off highway\n1.0\n1\n0\n0\n0\n1\n0\n0\n0\n2022\n9\n13\n2\n\n\n28\n9/12/2022\nUSA\nNY\nTesla runs off road, catches fire\n1.0\n1\n0\n0\n0\n0\n0\n0\n0\n2022\n9\n12\n2\n\n\n29\n9/7/2022\nUSA\nCA\nMotorcycle collides with Tesla\n1.0\n1\n0\n0\n0\n0\n0\n0\n0\n2022\n9\n7\n2\n\n\n\n\n\n\n\n\n\nLet’s see what type-0 accident is about.\nIt seems that this type of collision also has little to do with the maneuverability of Tesla.\n\n\nCode\ndf[df['cluster'] == 0].head(10)\n\n\n\n\n\n\n\n\n\nDate\nCountry\nState\nDescription\nDeaths\nTesla_driver\nTesla_occupant\nOther_vehicle\nCP\ntsla+cp\nModel\nClaimed\nVTAD\nevent_year\nevent_month\nevent_day\ncluster\n\n\n\n\n0\n1/17/2023\nUSA\nCA\nTesla crashes into back of semi\n1.0\n1\n0\n0\n0\n1\n0\n0\n0\n2023\n1\n17\n0\n\n\n1\n1/7/2023\nCanada\n-\nTesla crashes\n1.0\n1\n0\n0\n0\n1\n0\n0\n0\n2023\n1\n7\n0\n\n\n3\n12/22/2022\nUSA\nGA\nTesla crashes and burns\n1.0\n1\n0\n0\n0\n1\n0\n0\n0\n2022\n12\n22\n0\n\n\n4\n12/19/2022\nCanada\n-\nTesla crashes into storefront\n1.0\n0\n0\n0\n1\n1\n0\n0\n0\n2022\n12\n19\n0\n\n\n7\n12/11/2022\nUSA\nCA\nTesla crashes into wall\n1.0\n1\n0\n0\n0\n0\n0\n0\n0\n2022\n12\n11\n0\n\n\n13\n11/18/2022\nChina\n-\nTesla crashes into dump truck\n1.0\n1\n0\n0\n0\n1\n0\n0\n0\n2022\n11\n18\n0\n\n\n19\n10/19/2022\nUSA\nCA\nMulticar crash\n1.0\n1\n0\n0\n0\n1\n1\n0\n0\n2022\n10\n19\n0\n\n\n21\n10/12/2022\nUK\n-\nTesla crashes into ditch\n1.0\n1\n0\n0\n0\n1\n2\n0\n0\n2022\n10\n12\n0\n\n\n24\n9/18/2022\nUSA\nSC\nTesla crashes into tree, ignites\n2.0\n1\n1\n0\n0\n2\n0\n0\n0\n2022\n9\n18\n0\n\n\n25\n9/18/2022\nUSA\nMD\nMulti-car accident\n1.0\n0\n0\n1\n0\n0\n0\n0\n0\n2022\n9\n18\n0\n\n\n\n\n\n\n\n\n\nNumber of deaths in each type of accident\n\n\nCode\nfor i in range(0,5):\n    df[df[\"cluster\"]==i][\"Deaths\"].value_counts().sort_index().plot(figsize=(20,8))\n    plt.xlabel(\"total Death\")\n    plt.ylabel(\"ac type Counts\")\n    plt.title(\"ac type Counts - Death\")\n    plt.legend(\"01234\")\n\n\n\n\n\n\n\nDistribution of each type of accident at each year recorded\n\n\nCode\ndef make_Graph(feature):\n    x_s = df[feature].value_counts().sort_index().index\n    y_s = df[feature].value_counts().sort_index().values\n    y0_s = df[df[\"cluster\"]==0][feature].value_counts().sort_index()\n    y1_s = df[df[\"cluster\"]==1][feature].value_counts().sort_index()\n    y2_s = df[df[\"cluster\"]==2][feature].value_counts().sort_index()\n    y3_s = df[df[\"cluster\"]==3][feature].value_counts().sort_index()\n    y4_s = df[df[\"cluster\"]==4][feature].value_counts().sort_index()\n    def fill_y(x,y):\n        for i in x:\n            if i not in y.index:\n                y[i] = 0\n    fill_y(x_s,y0_s)\n    fill_y(x_s,y1_s)\n    fill_y(x_s,y2_s)\n    fill_y(x_s,y3_s)\n    fill_y(x_s,y4_s)\n    \n#     plt.figure(figsize=(10,8))\n    ax,ax0,ax1,ax2,ax3,ax4 = plt.gca(),plt.gca(),plt.gca(),plt.gca(),plt.gca(),plt.gca()\n\n    for i in range(len(x_s)):\n        height = y_s[i]\n        plt.text(x_s[i], height + 0.15, '%.1f' %height, ha='center', va='bottom', size = 12)\n\n    ax.bar(x_s, y_s, color='orange', linestyle='--')\n    ax.set_ylabel(feature+' - Counts', fontsize=10)\n    ax.tick_params('y', colors='blue') \n\n    ax0.plot(x_s, y0_s.sort_index().values, color='yellow', linestyle='--',label = \"0\")\n    ax1.plot(x_s, y1_s.sort_index().values, color='blue', linestyle='--',label = \"1\")\n    ax2.plot(x_s, y2_s.sort_index().values, color='red', linestyle='--',label = \"2\")\n    ax3.plot(x_s, y3_s.sort_index().values, color='pink', linestyle='--',label = \"3\")\n    ax4.plot(x_s, y4_s.sort_index().values, color='green', linestyle='--',label = \"4\")\n\n    ax1.set_xlabel(feature, fontsize=10)\n    plt.title(feature+\" Accident counts & Accident Type counts\",fontsize=13)\n    plt.tight_layout()\n    plt.legend()\n    plt.figure(figsize=(20,8))\nmake_Graph(\"event_year\")\n\n\n\n\n\n&lt;Figure size 1920x768 with 0 Axes&gt;\n\n\n\n\nConclusion:\nWe do not have enough evidence to claim that the maneuverability of Tesla is flawed, since most accidents are caused by human errors. However, more accidents did occur at latest years, which might be due to the largely increased number of Tesla on road."
  },
  {
    "objectID": "dataexplore.html#second-dataset-uk-road-safety-traffic-accidents-and-vehicles-gas-car",
    "href": "dataexplore.html#second-dataset-uk-road-safety-traffic-accidents-and-vehicles-gas-car",
    "title": "Data gathering",
    "section": "Second dataset: UK Road Safety: Traffic Accidents and Vehicles (gas car)",
    "text": "Second dataset: UK Road Safety: Traffic Accidents and Vehicles (gas car)\n\n\nCode\nfrom collections import Counter\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.simplefilter('ignore')\nfrom sklearn.pipeline import Pipeline\nimport scipy.stats as stats\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import boxcox\nimport pickle\nfrom numpy.random import seed\nseed(862)\nfrom tensorflow.random import set_seed\nset_seed(862)\ndata = pd.read_csv(\"./Data/RoadAccident.csv\")\ndata.drop(['Accident_Index','Datetime'], axis = 1,inplace=True) \nd = {\"Feature\":[i for i in data.columns]    ,\"Nunique\" :data.nunique().values ,'Type' : data.dtypes.values, \"No: of nulls\" : data.isnull().sum() }\ndescription = pd.DataFrame(data = d)\ndescription\ndata[\"Season\"]=data[\"Season\"].astype(str)\ndata[\"Month_of_Year\"]=data[\"Month_of_Year\"].astype(str)\ndata[\"Day_of_Week\"]=data[\"Day_of_Week\"].astype(str)\ndata[\"Year\"]=data[\"Year\"].astype(str)\ndata[\"Number_of_Vehicles\"]=data[\"Number_of_Vehicles\"].astype(str)\nCounter(data['Accident_Severity'])\n\n\nCounter({'Slight': 56705, 'Fatal_Serious': 18845})\n\n\n\nPlot count plots for the categorical data and histogram for numerical data\n\n\nCode\ncat_data  = data.select_dtypes(exclude=[np.number])\nfor i in cat_data:  \n  plt.figure(figsize=(10,10))# Creating an empty plot \n  ax=sns.countplot(x=cat_data[i],hue=data[\"Accident_Severity\"])# Countplot of airlines\n  plt.tick_params(labelsize=10)# changing the label sizes  \n  plt.ylabel(\"Count\" ,fontsize=10) #Adding y-label\n  #plt.title(\"\\n\", cat_data.columns.values,\"\\n\",fontsize=25) # Adding plot title\n  for p in ax.patches:\n      ax.annotate('{}'.format(p.get_height()),(p.get_x()+0.25,p.get_height()+5)) # Adding the count above the bars\n  plt.show()"
  },
  {
    "objectID": "dataclean.html#first-dataset-tesla-deaths---deaths",
    "href": "dataclean.html#first-dataset-tesla-deaths---deaths",
    "title": "Data gathering",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndf = pd.read_csv(\"./Data/Tesla Deaths - Deaths.csv\")\n\n\n\n\n\n\nCode\nmsno.heatmap(df)\n\n\n\n\n\n\n\n\n\n\n\nCode\nnew_df = pd.DataFrame()\nfor i in range(len(df.columns[:14]),1,-1):\n    new_df.insert(0,df.columns[i],df[df.columns[i]])\ndf = new_df\ndf.head()\n\n\n\n\n\n\n\n\n\nDate\nCountry\nState\nDescription\nDeaths\nTesla driver\nTesla occupant\nOther vehicle\nCyclists/ Peds\nTSLA+cycl / peds\nModel\nAutopilot claimed\nVerified Tesla Autopilot Deaths\n\n\n\n\n0\n1/17/2023\nUSA\nCA\nTesla crashes into back of semi\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n1\n1/7/2023\nCanada\n-\nTesla crashes\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n2\n1/7/2023\nUSA\nWA\nTesla hits pole, catches on fire\n1.0\n-\n1\n-\n-\n1\n-\n-\n-\n\n\n3\n12/22/2022\nUSA\nGA\nTesla crashes and burns\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n4\n12/19/2022\nCanada\n-\nTesla crashes into storefront\n1.0\n-\n-\n-\n1\n1\n-\n-\n-\n\n\n\n\n\n\n\n\n\nCode\nmsno.bar(df)\n\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n\n\n\n\nCode\nfor i in range(5,10):\n    df[df.columns[i]] = df[df.columns[i]].fillna(\"-\")\nfor i in range(11,13):\n    df[df.columns[i]] = df[df.columns[i]].fillna('-')\nmsno.bar(df)\n\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n\n\n\n\nCode\ndf = df.dropna()\nmsno.bar(df)\n\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n\nCode\ndf.columns = ['Date','Country','State','Description','Deaths',\"Tesla_driver\",\"Tesla_occupant\",\"Other_vehicle\",\"CP\",\"tsla+cp\",\"Model\",\"Claimed\",\"VTAD\"]\ndf.head()\n\n\n\n\n\n\n\n\n\nDate\nCountry\nState\nDescription\nDeaths\nTesla_driver\nTesla_occupant\nOther_vehicle\nCP\ntsla+cp\nModel\nClaimed\nVTAD\n\n\n\n\n0\n1/17/2023\nUSA\nCA\nTesla crashes into back of semi\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n1\n1/7/2023\nCanada\n-\nTesla crashes\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n2\n1/7/2023\nUSA\nWA\nTesla hits pole, catches on fire\n1.0\n-\n1\n-\n-\n1\n-\n-\n-\n\n\n3\n12/22/2022\nUSA\nGA\nTesla crashes and burns\n1.0\n1\n-\n-\n-\n1\n-\n-\n-\n\n\n4\n12/19/2022\nCanada\n-\nTesla crashes into storefront\n1.0\n-\n-\n-\n1\n1\n-\n-\n-\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf.to_csv('./cleandata/cleanTelsa.csv', index=False)"
  }
]